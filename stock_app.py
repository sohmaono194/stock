import streamlit as st
import requests
import zipfile
import io
import pandas as pd
import chardet
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
import japanize_matplotlib

# åˆæœŸè¨­å®š
load_dotenv()
API_KEY = os.environ.get("EDINET_API_KEY")
API_BASE = "https://disclosure.edinet-fsa.go.jp/api/v2"

st.title("ğŸ“Š EDINET è²¡å‹™ãƒ‡ãƒ¼ã‚¿ è‡ªå‹•å–å¾— & ã‚°ãƒ©ãƒ•åŒ–ã‚¢ãƒ—ãƒª")

if not API_KEY:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ã« 'EDINET_API_KEY' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# docIDæ¤œç´¢ï¼ˆå ±å‘Šæ›¸ï¼‰
def find_docid(company_name, days=90):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    today = datetime.today()

    for i in range(days):
        date = today - timedelta(days=i)
        if date.weekday() >= 5:
            continue
        try:
            res = requests.get(f"{API_BASE}/documents.json",
                               params={"date": date.strftime("%Y-%m-%d"), "type": 2},
                               headers=headers, timeout=10)
            for item in res.json().get("results", []):
                name = item.get("filerName", "")
                desc = item.get("docDescription", "")
                if company_name in name and "å ±å‘Šæ›¸" in desc:
                    return item["docID"], desc
        except:
            continue
    return None, None

# CSVæŠ½å‡º
def parse_csv_metrics(df):
    if not set(["é …ç›®ID", "é‡‘é¡"]).issubset(df.columns):
        raise ValueError("CSVã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    metrics = {}
    key_map = {
        "NetSales": "å£²ä¸Šé«˜", "OperatingIncome": "å–¶æ¥­åˆ©ç›Š",
        "OrdinaryIncome": "çµŒå¸¸åˆ©ç›Š", "NetIncome": "ç´”åˆ©ç›Š"
    }
    for key, label in key_map.items():
        match = df[df["é …ç›®ID"].astype(str).str.contains(key, na=False)]
        if not match.empty:
            try:
                metrics[label] = int(match.iloc[0]["é‡‘é¡"])
            except:
                metrics[label] = match.iloc[0]["é‡‘é¡"]
        else:
            metrics[label] = None
    return metrics

# XBRLæŠ½å‡º
def parse_xbrl_metrics(xml_data):
    soup = BeautifulSoup(xml_data, "xml")
    results = {}
    tag_map = {
        "å£²ä¸Šé«˜": ["NetSales", "NetSalesConsolidated"],
        "å–¶æ¥­åˆ©ç›Š": ["OperatingIncome", "OperatingIncomeConsolidated"],
        "çµŒå¸¸åˆ©ç›Š": ["OrdinaryIncome", "OrdinaryIncomeConsolidated"],
        "ç´”åˆ©ç›Š": ["NetIncome", "Profit", "NetIncomeAttributableToOwnersOfParent"],
    }
    for label, tags in tag_map.items():
        for tag in tags:
            found = soup.find(tag)
            if found and found.text.strip().isdigit():
                results[label] = int(found.text.strip())
                break
        if label not in results:
            results[label] = None
    return results

# ZIPå–å¾—ã¨è§£æ
def fetch_and_parse_zip(doc_id):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    # CSVå„ªå…ˆ
    try:
        res = requests.get(f"{API_BASE}/documents/{doc_id}", params={"type": 5}, headers=headers, timeout=15)
        if "zip" in res.headers.get("Content-Type", ""):
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                for name in z.namelist():
                    if name.endswith(".csv"):
                        with z.open(name) as f:
                            raw = f.read()
                            enc = chardet.detect(raw)["encoding"]
                            df = pd.read_csv(io.BytesIO(raw), encoding=enc)
                            return parse_csv_metrics(df), "CSV"
    except Exception as e:
        st.warning(f"[CSVå¤±æ•—] {e}")
    # XBRL fallback
    try:
        res = requests.get(f"{API_BASE}/documents/{doc_id}", params={"type": 1}, headers=headers, timeout=15)
        if "zip" in res.headers.get("Content-Type", ""):
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                for name in z.namelist():
                    if "PublicDoc" in name and name.endswith(".xbrl"):
                        with z.open(name) as f:
                            return parse_xbrl_metrics(f.read()), "XBRL"
    except Exception as e:
        st.warning(f"[XBRLå¤±æ•—] {e}")
    raise ValueError("ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# UIæœ¬ä½“
company = st.text_input("ä¼æ¥­åã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šï¼‰")
if st.button("è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—"):
    if not company:
        st.warning("ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("docIDæ¤œç´¢ä¸­..."):
            doc_id, desc = find_docid(company)
            if not doc_id:
                st.error("è©²å½“ã™ã‚‹å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.success(f"{desc}ï½œdocID: {doc_id}")
                try:
                    metrics, source = fetch_and_parse_zip(doc_id)
                    df = pd.DataFrame([{"æŒ‡æ¨™": k, "é‡‘é¡": v} for k, v in metrics.items()])
                    st.subheader(f"{source}ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸè²¡å‹™æŒ‡æ¨™")
                    st.table(df)

                    st.subheader("ğŸ“Š ã‚°ãƒ©ãƒ•")
                    df_plot = df[df["é‡‘é¡"].notnull()]
                    fig, ax = plt.subplots()
                    ax.bar(df_plot["æŒ‡æ¨™"], df_plot["é‡‘é¡"])
                    ax.set_ylabel("é‡‘é¡ï¼ˆå††ï¼‰")
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã¾ãŸã¯è§£æã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
