import streamlit as st
import requests
import zipfile
import io
import pandas as pd
import os
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# .envã‹ã‚‰APIã‚­ãƒ¼èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.environ.get("EDINET_API_KEY")
if not API_KEY:
    st.error("APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`.env` ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæ—¥æœ¬èªè¡¨ç¤ºï¼‰
plt.rcParams["font.family"] = "MS Gothic"  # Macã®å ´åˆã¯ "AppleGothic" ã«å¤‰æ›´

st.title("ğŸ“Š EDINET è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¢ãƒ—ãƒªï¼ˆCSVã¾ãŸã¯XBRL + ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼‰")

# ----------------------------
# docID æ¤œç´¢
# ----------------------------
def find_docid(company_name, days=180):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    today = datetime.today()

    for _ in range(days):
        today -= timedelta(days=1)
        if today.weekday() >= 5:  # åœŸæ—¥ã‚¹ã‚­ãƒƒãƒ—
            continue
        url = "https://api.edinet-fsa.go.jp/api/v2/documents.json"
        params = {"date": today.strftime("%Y-%m-%d"), "type": 2}
        try:
            res = requests.get(url, headers=headers, params=params, timeout=10)
            res.raise_for_status()
            for item in res.json().get("results", []):
                if company_name in item.get("filerName", "") and "å ±å‘Šæ›¸" in item.get("docDescription", ""):
                    return item.get("docID"), item.get("docDescription")
        except Exception:
            continue
    return None, None

# ----------------------------
# ZIP å–å¾— & å±•é–‹
# ----------------------------
def download_and_extract_zip(doc_id, file_type=5):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    url = f"https://api.edinet-fsa.go.jp/api/v2/documents/{doc_id}"
    params = {"type": file_type}
    res = requests.get(url, headers=headers, params=params)
    if "zip" not in res.headers.get("Content-Type", ""):
        return None
    return zipfile.ZipFile(io.BytesIO(res.content))

# ----------------------------
# è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆCSVï¼‰
# ----------------------------
def parse_csv_metrics(df):
    if not set(["é …ç›®ID", "é‡‘é¡"]).issubset(df.columns):
        raise ValueError("CSVã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    metrics = {}
    key_map = {
        "NetSales": "å£²ä¸Šé«˜",
        "OperatingIncome": "å–¶æ¥­åˆ©ç›Š",
        "OrdinaryIncome": "çµŒå¸¸åˆ©ç›Š",
        "NetIncome": "ç´”åˆ©ç›Š"
    }

    for key, label in key_map.items():
        match = df[df["é …ç›®ID"].astype(str).str.contains(key, na=False)]
        if not match.empty:
            try:
                metrics[label] = int(match.iloc[0]["é‡‘é¡"])
            except:
                metrics[label] = match.iloc[0]["é‡‘é¡"]
        else:
            metrics[label] = None

    return metrics

# ----------------------------
# è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆXBRLï¼‰
# ----------------------------
def parse_xbrl_metrics(xml_data):
    soup = BeautifulSoup(xml_data, "xml")
    tag_map = {
        "å£²ä¸Šé«˜": ["NetSales", "NetSalesConsolidated"],
        "å–¶æ¥­åˆ©ç›Š": ["OperatingIncome"],
        "çµŒå¸¸åˆ©ç›Š": ["OrdinaryIncome"],
        "ç´”åˆ©ç›Š": ["NetIncome", "Profit"]
    }
    result = {}
    for label, tags in tag_map.items():
        for tag in tags:
            val = soup.find(tag)
            if val and val.text.strip().isdigit():
                result[label] = int(val.text.strip())
                break
        if label not in result:
            result[label] = None
    return result

# ----------------------------
# ã‚°ãƒ©ãƒ•æç”»
# ----------------------------
def plot_metrics(metrics: dict):
    labels = list(metrics.keys())
    values = [v if isinstance(v, (int, float)) else 0 for v in metrics.values()]
    fig, ax = plt.subplots()
    ax.bar(labels, values)
    ax.set_title("è²¡å‹™æŒ‡æ¨™")
    ax.set_ylabel("é‡‘é¡ï¼ˆç™¾ä¸‡å††ï¼‰")
    st.pyplot(fig)

# ----------------------------
# UI
# ----------------------------
company = st.text_input("ä¼æ¥­åã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šæ ªå¼ä¼šç¤¾ï¼‰")
if st.button("ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨è¡¨ç¤º"):
    if not company:
        st.warning("ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    with st.spinner("docIDã‚’æ¤œç´¢ä¸­..."):
        doc_id, desc = find_docid(company)
        if not doc_id:
            st.error("è©²å½“ã™ã‚‹å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.stop()
        st.success(f"docID: {doc_id}ï½œ{desc}")

    with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ä¸­..."):
        z = download_and_extract_zip(doc_id, file_type=5)
        if not z:
            z = download_and_extract_zip(doc_id, file_type=1)
            if not z:
                st.error("ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.stop()
            else:
                for name in z.namelist():
                    if name.endswith(".xbrl"):
                        with z.open(name) as f:
                            xml = f.read()
                            metrics = parse_xbrl_metrics(xml)
                            break
        else:
            for name in z.namelist():
                if name.endswith(".csv"):
                    with z.open(name) as f:
                        df = pd.read_csv(f, encoding="utf-8", low_memory=False)
                        metrics = parse_csv_metrics(df)
                        break

    st.subheader("ğŸ“Š æŠ½å‡ºã•ã‚ŒãŸè²¡å‹™æŒ‡æ¨™")
    st.dataframe(pd.DataFrame(metrics.items(), columns=["æŒ‡æ¨™", "é‡‘é¡"]))
    plot_metrics(metrics)
