import os
import io
import zipfile
import requests
import chardet
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import matplotlib.pyplot as plt

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆStreamlit Cloud å‘ã‘ï¼‰
plt.rcParams['font.family'] = 'Noto Sans CJK JP'

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ APIã‚­ãƒ¼å–å¾—
load_dotenv()
API_KEY = os.environ.get("EDINET_API_KEY")
API_ENDPOINT = "https://disclosure.edinet-fsa.go.jp/api/v2"

st.title("ğŸ“¦ ä¼æ¥­åã‹ã‚‰EDINET ZIPã‚’å–å¾—â†’è§£å‡â†’è²¡å‹™æŒ‡æ¨™ã‚’å¯è¦–åŒ–")

if not API_KEY:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ã« 'EDINET_API_KEY' ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# docID æ¤œç´¢ï¼ˆå››åŠæœŸå ±å‘Šæ›¸ã‚’å„ªå…ˆï¼‰
# ----------------------------
def search_docid(company_name, days_back=180):
    date = datetime.today()
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    for _ in range(days_back):
        date -= timedelta(days=1)
        if date.weekday() >= 5:
            continue
        url = f"{API_ENDPOINT}/documents.json"
        params = {"date": date.strftime("%Y-%m-%d"), "type": 2}
        try:
            res = requests.get(url, headers=headers, params=params, timeout=10)
            res.raise_for_status()
            for doc in res.json().get("results", []):
                if company_name in doc.get("filerName", "") and "å››åŠæœŸå ±å‘Šæ›¸" in doc.get("docDescription", ""):
                    return doc.get("docID"), doc.get("filerName"), doc.get("docDescription"), doc.get("csvFlag", "0")
        except:
            continue
    return None, None, None, "0"

# ----------------------------
# ZIPã‚’å–å¾—ã—ã¦ä¿å­˜ãƒ»è§£å‡
# ----------------------------
def download_and_extract_zip(docID, type=5):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    url = f"{API_ENDPOINT}/documents/{docID}"
    params = {"type": type}
    res = requests.get(url, headers=headers, params=params, timeout=20)
    if "zip" not in res.headers.get("Content-Type", ""):
        raise ValueError("ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    temp_dir = f"temp_{docID}"
    os.makedirs(temp_dir, exist_ok=True)

    with zipfile.ZipFile(io.BytesIO(res.content)) as z:
        z.extractall(temp_dir)

    return temp_dir

# ----------------------------
# CSVã‹ã‚‰æŒ‡æ¨™æŠ½å‡º
# ----------------------------
def extract_from_csv_folder(folder_path):
    for file in os.listdir(folder_path):
        if file.endswith(".csv"):
            with open(os.path.join(folder_path, file), "rb") as f:
                raw = f.read()
                enc = chardet.detect(raw)["encoding"]
                df = pd.read_csv(io.BytesIO(raw), encoding=enc)
                return extract_financials_from_df(df)
    return {}

# ----------------------------
# XBRLã‹ã‚‰æŒ‡æ¨™æŠ½å‡º
# ----------------------------
def extract_from_xbrl_folder(folder_path):
    for file in os.listdir(folder_path):
        if file.endswith(".xbrl"):
            with open(os.path.join(folder_path, file), "rb") as f:
                xml = f.read()
                return extract_from_xbrl(xml)
    return {}

def extract_financials_from_df(df):
    if not set(["é …ç›®ID", "é‡‘é¡"]).issubset(df.columns):
        return {}
    keywords = {
        "å£²ä¸Šé«˜": "NetSales",
        "å–¶æ¥­åˆ©ç›Š": "OperatingIncome",
        "çµŒå¸¸åˆ©ç›Š": "OrdinaryIncome",
        "ç´”åˆ©ç›Š": "NetIncome"
    }
    results = {}
    for jp, en in keywords.items():
        match = df[df["é …ç›®ID"].astype(str).str.contains(en, na=False)]
        if not match.empty:
            results[jp] = int(match.iloc[0]["é‡‘é¡"])
    return results

def extract_from_xbrl(xml):
    soup = BeautifulSoup(xml, "xml")
    tags = {
        "å£²ä¸Šé«˜": ["NetSales", "NetSalesConsolidated"],
        "å–¶æ¥­åˆ©ç›Š": ["OperatingIncome", "OperatingIncomeConsolidated"],
        "çµŒå¸¸åˆ©ç›Š": ["OrdinaryIncome", "OrdinaryIncomeConsolidated"],
        "ç´”åˆ©ç›Š": ["NetIncome", "NetIncomeAttributableToOwnersOfParent"]
    }
    result = {}
    for label, options in tags.items():
        for tag in options:
            found = soup.find(tag)
            if found and found.text.strip().isdigit():
                result[label] = int(found.text.strip())
                break
        if label not in result:
            result[label] = None
    return result

# ----------------------------
# ã‚°ãƒ©ãƒ•æç”»
# ----------------------------
def plot_metrics(metrics, company_name):
    labels = list(metrics.keys())
    values = list(metrics.values())

    fig, ax = plt.subplots()
    ax.bar(labels, values)
    ax.set_title(f"{company_name} ã®è²¡å‹™æŒ‡æ¨™")
    ax.set_ylabel("é‡‘é¡ï¼ˆç™¾ä¸‡å††ï¼‰")
    plt.xticks(rotation=30)
    st.pyplot(fig)

# ----------------------------
# UI éƒ¨åˆ†
# ----------------------------
st.header("ğŸ” ä¼æ¥­åã‹ã‚‰è²¡å‹™ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãƒ»ZIPä¿å­˜")
company = st.text_input("ä¾‹ï¼šãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šæ ªå¼ä¼šç¤¾")

if st.button("ZIPå–å¾—ãƒ»æŒ‡æ¨™æŠ½å‡ºãƒ»ã‚°ãƒ©ãƒ•è¡¨ç¤º"):
    if not company:
        st.warning("ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner("docIDæ¤œç´¢ä¸­..."):
            docID, name, desc, csv_flag = search_docid(company)
        if not docID:
            st.error("docIDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.success(f"âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š{name}ï½œ{desc}ï½œdocID: {docID}ï½œCSV: {csv_flag}")
            with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»è§£å‡ä¸­..."):
                folder = download_and_extract_zip(docID, type=5 if csv_flag == "1" else 1)

            st.write(f"ğŸ“ è§£å‡å…ˆï¼š `{folder}`")

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            metrics = extract_from_csv_folder(folder) if csv_flag == "1" else extract_from_xbrl_folder(folder)

            if not metrics:
                st.error("è²¡å‹™æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.subheader(f"ğŸ“ˆ è²¡å‹™æŒ‡æ¨™ï¼ˆ{desc}ï¼‰")
                st.dataframe(pd.DataFrame(metrics.items(), columns=["æŒ‡æ¨™", "é‡‘é¡"]))
                plot_metrics(metrics, name)
