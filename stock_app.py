import os
import time
import zipfile
import io

import streamlit as st
import pandas as pd
import requests
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from dotenv import load_dotenv
from datetime import datetime, timedelta
import chardet

# ãƒ•ã‚©ãƒ³ãƒˆæŒ‡å®šï¼ˆWindowsç”¨: MS Gothicï¼‰
plt.rcParams["font.family"] = "MS Gothic"

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
API_KEY = os.getenv("EDINET_API_KEY")
API_ENDPOINT = "https://disclosure.edinet-fsa.go.jp/api/v2"

st.title("ğŸ“Š EDINET è²¡å‹™ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚¢ãƒ—ãƒª")

if not API_KEY:
    st.error("EDINET_API_KEY ãŒ .env ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.stop()

# -----------------------------
# docIDæ¤œç´¢é–¢æ•°ï¼ˆå ±å‘Šæ›¸ã‚’å¯¾è±¡ï¼‰
# -----------------------------
def find_docid(company_name, days_back=90):
    today = datetime.today()
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    for i in range(days_back):
        date_str = (today - timedelta(days=i)).strftime("%Y-%m-%d")
        params = {"date": date_str, "type": 2}
        try:
            res = requests.get(f"{API_ENDPOINT}/documents.json", headers=headers, params=params, timeout=10)
            res.raise_for_status()
            results = res.json().get("results", [])
            for item in results:
                if company_name in item.get("filerName", "") and "å ±å‘Šæ›¸" in item.get("docDescription", ""):
                    return item.get("docID"), item.get("docDescription", "")
        except:
            continue
    return None, None

# -----------------------------
# ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‹è§£å‡å‡¦ç†
# -----------------------------
def download_and_extract_zip(docID, extract_dir):
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    params = {"type": 5}
    url = f"{API_ENDPOINT}/documents/{docID}"
    res = requests.get(url, headers=headers, params=params, timeout=15)

    if res.status_code != 200 or "zip" not in res.headers.get("Content-Type", ""):
        return False

    os.makedirs(extract_dir, exist_ok=True)
    temp_zip_path = os.path.join(extract_dir, f"{docID}.zip")

    with open(temp_zip_path, "wb") as f:
        f.write(res.content)

    with zipfile.ZipFile(temp_zip_path, "r") as z:
        z.extractall(extract_dir)

    os.remove(temp_zip_path)
    return True

# -----------------------------
# è²¡å‹™æŒ‡æ¨™ã®æŠ½å‡º
# -----------------------------
def extract_metrics_from_csv(folder):
    result = {}
    for file in os.listdir(folder):
        if file.endswith(".csv"):
            path = os.path.join(folder, file)
            raw = open(path, "rb").read()
            enc = chardet.detect(raw)["encoding"]
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc)
                if {"é …ç›®ID", "é‡‘é¡"}.issubset(df.columns):
                    for key in ["NetSales", "OperatingIncome", "OrdinaryIncome", "NetIncome"]:
                        match = df[df["é …ç›®ID"].str.contains(key, na=False)]
                        if not match.empty:
                            result[key] = match.iloc[0]["é‡‘é¡"]
            except:
                continue
    return result

# -----------------------------
# ã‚°ãƒ©ãƒ•æç”»
# -----------------------------
def plot_metrics(metrics):
    if not metrics:
        st.warning("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    labels = {"NetSales": "å£²ä¸Šé«˜", "OperatingIncome": "å–¶æ¥­åˆ©ç›Š", "OrdinaryIncome": "çµŒå¸¸åˆ©ç›Š", "NetIncome": "ç´”åˆ©ç›Š"}
    values = [int(metrics[k]) for k in metrics if metrics[k].isdigit()]
    keys = [labels[k] for k in metrics if metrics[k].isdigit()]

    fig, ax = plt.subplots()
    ax.bar(keys, values)
    ax.set_ylabel("é‡‘é¡ï¼ˆå˜ä½: ç™¾ä¸‡å††ï¼‰")
    ax.set_title("æŠ½å‡ºã•ã‚ŒãŸè²¡å‹™æŒ‡æ¨™")
    st.pyplot(fig)

# -----------------------------
# Streamlit UIæœ¬ä½“
# -----------------------------
company = st.text_input("ä¼æ¥­åã‚’å…¥åŠ›ï¼ˆä¾‹: ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šæ ªå¼ä¼šç¤¾ï¼‰")

if st.button("ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è¡¨ç¤º"):
    if not company:
        st.warning("ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()

    with st.spinner("EDINETã‹ã‚‰docIDã‚’æ¤œç´¢ä¸­..."):
        docID, description = find_docid(company)

    if not docID:
        st.error("è©²å½“ã™ã‚‹å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    else:
        st.success(f"docID: {docID}ï½œ{description}")
        extract_dir = f"temp_{docID}"
        with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£å‡ä¸­..."):
            if download_and_extract_zip(docID, extract_dir):
                metrics = extract_metrics_from_csv(extract_dir)
                plot_metrics(metrics)
            else:
                st.error("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã¾ãŸã¯è§£å‡ã«å¤±æ•—ã—ã¾ã—ãŸ")
