import streamlit as st
import datetime
import os
import json
import urllib.parse
import urllib.request
from typing import List, Dict, Union
from dotenv import load_dotenv
import zipfile
import io

# --- ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰ ---
load_dotenv()
EDINET_API_KEY = os.environ.get('EDINET_API_KEY')

if not EDINET_API_KEY:
    st.error("`.env` ã« `EDINET_API_KEY` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# --- EDINET API åŸºæœ¬é–¢æ•° ---
def disclosure_documents(date: Union[str, datetime.date], type: int = 2) -> Dict:
    if isinstance(date, datetime.date):
        date_str = date.strftime('%Y-%m-%d')
    elif isinstance(date, str):
        date_str = date
    else:
        raise TypeError("Date must be string (YYYY-MM-DD) or datetime.date")

    url = "https://disclosure.edinet-fsa.go.jp/api/v2/documents.json"
    params = {
        "date": date_str,
        "type": type,
        "Subscription-Key": EDINET_API_KEY
    }
    query_string = urllib.parse.urlencode(params)
    full_url = f"{url}?{query_string}"

    with urllib.request.urlopen(full_url) as response:
        return json.loads(response.read().decode('utf-8'))

def get_document(doc_id: str) -> bytes:
    url = f'https://api.edinet-fsa.go.jp/api/v2/documents/{doc_id}'
    params = {
        "type": 5,  # CSV zip
        "Subscription-Key": EDINET_API_KEY
    }
    query_string = urllib.parse.urlencode(params)
    full_url = f'{url}?{query_string}'
    with urllib.request.urlopen(full_url) as response:
        return response.read()

# --- UIæ§‹æˆ ---
st.title("ğŸ“„ EDINET é–‹ç¤ºæ›¸é¡ æ¤œç´¢ï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

col1, col2 = st.columns(2)
with col1:
    start_date = st.date_input("é–‹å§‹æ—¥", datetime.date.today() - datetime.timedelta(days=7))
with col2:
    end_date = st.date_input("çµ‚äº†æ—¥", datetime.date.today())

edinet_codes_input = st.text_input("EDINETã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šå¯ã€ä¾‹ï¼šE03614,E03615ï¼‰")
doc_type_codes_input = st.text_input("æ›¸é¡ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼š140,160ï¼‰")

if st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ"):
    if start_date > end_date:
        st.error("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã«ã—ã¦ãã ã•ã„")
        st.stop()

    codes = [c.strip() for c in edinet_codes_input.split(",") if c.strip()]
    doc_types = [d.strip() for d in doc_type_codes_input.split(",") if d.strip()]
    results = []

    with st.spinner("EDINETã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
        current_date = start_date
        while current_date <= end_date:
            try:
                docs_res = disclosure_documents(date=current_date)
                for doc in docs_res.get("results", []):
                    if (not codes or doc['edinetCode'] in codes) and (not doc_types or doc['docTypeCode'] in doc_types):
                        results.append(doc)
            except Exception as e:
                st.warning(f"{current_date} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            current_date += datetime.timedelta(days=1)

    if not results:
        st.warning("è©²å½“ã™ã‚‹æ›¸é¡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.success(f"{len(results)} ä»¶ã®æ›¸é¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        df_results = []
        for r in results:
            df_results.append({
                "docID": r.get("docID"),
                "ä¼æ¥­å": r.get("filerName"),
                "EDINETã‚³ãƒ¼ãƒ‰": r.get("edinetCode"),
                "æ›¸é¡ç¨®åˆ¥": r.get("docTypeCode"),
                "æå‡ºæ—¥": r.get("submitDateTime"),
                "èª¬æ˜": r.get("docDescription")
            })
        st.dataframe(df_results)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        for doc in results:
            doc_id = doc['docID']
            filer = doc.get("filerName", "Unknown")
            file_name = f"{doc_id}_{filer}.zip".replace(" ", "_")
            zip_data = get_document(doc_id)
            st.download_button(
                label=f"â¬‡ {filer} ã®CSV ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=zip_data,
                file_name=file_name,
                mime="application/zip"
            )
