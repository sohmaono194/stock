import streamlit as st
import requests
import zipfile
import io
import pandas as pd
import chardet
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv

# .env ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
API_KEY = os.environ.get("EDINET_API_KEY")

st.title("ğŸ“Š ä¼æ¥­åã‹ã‚‰EDINETè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å–å¾—ãƒ»å¯è¦–åŒ–")

if not API_KEY:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ç’°å¢ƒå¤‰æ•° 'EDINET_API_KEY' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# docIDã‚’ä¼æ¥­åã§æ¤œç´¢
# ----------------------------
def search_docid_by_company_name(company_name, days_back=180):
    date = datetime.today()
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    for _ in range(days_back):
        date -= timedelta(days=1)
        if date.weekday() >= 5:  # åœŸæ—¥ã‚’ã‚¹ã‚­ãƒƒãƒ—
            continue
        url = "https://api.edinet-fsa.go.jp/api/v2/documents.json"
        params = {"date": date.strftime('%Y-%m-%d'), "type": 2}
        try:
            res = requests.get(url, headers=headers, params=params, timeout=10)
            res.raise_for_status()
            for doc in res.json().get("results", []):
                name = doc.get("filerName", "")
                desc = doc.get("docDescription", "")
                if company_name in name and any(kw in desc for kw in ["æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸", "å››åŠæœŸå ±å‘Šæ›¸", "åŠæœŸå ±å‘Šæ›¸"]):
                    return doc.get("docID"), name, desc
        except Exception:
            continue
    return None, None, None

# ----------------------------
# docIDã‹ã‚‰CSVã‚’å–å¾—
# ----------------------------
def fetch_csv_from_docid(doc_id):
    url = f"https://api.edinet-fsa.go.jp/api/v2/documents/{doc_id}"
    headers = {"Ocp-Apim-Subscription-Key": API_KEY}
    params = {"type": 5}
    res = requests.get(url, headers=headers, params=params, timeout=20)
    if "zip" not in res.headers.get("Content-Type", ""):
        raise ValueError("ã“ã®docIDã«ã¯ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    with zipfile.ZipFile(io.BytesIO(res.content)) as z:
        candidates = []
        for file_name in z.namelist():
            if file_name.endswith(".csv"):
                with z.open(file_name) as f:
                    raw = f.read()
                    encoding = chardet.detect(raw)["encoding"]
                    try:
                        df = pd.read_csv(io.BytesIO(raw), encoding=encoding)
                        if "é …ç›®ID" in df.columns and "é‡‘é¡" in df.columns:
                            candidates.append((df, file_name, len(df)))
                    except Exception:
                        continue
        if not candidates:
            raise FileNotFoundError("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        # è¡Œæ•°ãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã‚’é¸ã¶
        candidates.sort(key=lambda x: x[2], reverse=True)
        return candidates[0][0], candidates[0][1]

# ----------------------------
# è²¡å‹™æŒ‡æ¨™ã‚’æŠ½å‡º
# ----------------------------
def extract_financial_metrics(df):
    keywords = {
        "NetSales": "å£²ä¸Šé«˜",
        "OperatingIncome": "å–¶æ¥­åˆ©ç›Š",
        "OrdinaryIncome": "çµŒå¸¸åˆ©ç›Š",
        "NetIncome": "å½“æœŸç´”åˆ©ç›Š"
    }
    extracted = []
    for kw, label in keywords.items():
        matches = df[df["é …ç›®ID"].astype(str).str.contains(kw, na=False)]
        if not matches.empty:
            latest = matches.iloc[0]  # æœ€æ–°ã®è¡Œã‚’é¸ã¶
            amount = latest.get("é‡‘é¡", "")
            try:
                amount_fmt = f"{int(amount):,}"
            except:
                amount_fmt = amount
            extracted.append({"æŒ‡æ¨™": label, "è‹±èªID": kw, "é‡‘é¡": amount_fmt})
    return pd.DataFrame(extracted)

# ----------------------------
# UI
# ----------------------------
st.header("ğŸ” ä¼æ¥­åã‹ã‚‰docIDã‚’æ¤œç´¢ã—ã€è²¡å‹™CSVã‚’å–å¾—")
company = st.text_input("ä¼æ¥­åã‚’å…¥åŠ›ï¼ˆä¾‹: ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šæ ªå¼ä¼šç¤¾ï¼‰")

if st.button("æ¤œç´¢ã—ã¦è²¡å‹™ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
    if not company:
        st.warning("ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner("EDINETã§docIDã‚’æ¤œç´¢ä¸­..."):
            doc_id, name, desc = search_docid_by_company_name(company)
            if not doc_id:
                st.error("è©²å½“ã™ã‚‹ä¼æ¥­ã®docIDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆCSVå¯¾å¿œæ›¸é¡ã§ãªã„å¯èƒ½æ€§ã‚ã‚Šï¼‰")
            else:
                st.success(f"âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š{name}ï½œ{desc}ï½œdocID: {doc_id}")
                try:
                    df, fname = fetch_csv_from_docid(doc_id)
                    st.write(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«å: {fname}")
                    st.dataframe(df.head(30))

                    st.subheader("ğŸ“ˆ æŠ½å‡ºã•ã‚ŒãŸè²¡å‹™æŒ‡æ¨™")
                    metrics_df = extract_financial_metrics(df)
                    if metrics_df.empty:
                        st.warning("ä¸»è¦ãªè²¡å‹™æŒ‡æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.table(metrics_df)
                        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
                        st.bar_chart(metrics_df.set_index("æŒ‡æ¨™")["é‡‘é¡"].astype(str).str.replace(",", "").astype(float))
                except Exception as e:
                    st.error(f"CSVã®å–å¾—ã¾ãŸã¯è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
